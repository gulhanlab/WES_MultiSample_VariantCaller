include required(classpath("application"))


# Adapted from https://gitlab.unimelb.edu.au/bioscience/escalibur/-/blob/master/workflow-runtime.slurm.config

docker {
  hash-lookup {
    enabled = "false"
  }
}

##### Cromwell aborts jobs when a control-C command is received.
system {
    abort-jobs-on-terminate = true
    memory-retry-error-keys = ["OutOfMemory", "Killed"]
}

workflow-options {
    workflow-log-dir = "cromwell-workflow-logs"
    workflow-log-temporary = false
}

backend {
    default = SLURM
        
    providers {
        SLURM {
            actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
            config {
                root = "cromwell-slurm-exec"
                run-in-background = true
                concurrent-job-limit = 400

                filesystems {
                    local {
                        localization: [
                            # soft link does not work for docker with --contain.
                            # Hard links won't work across file systems
                            "soft-link", "hard-link", "cached-copy", "copy"
                        ]
                    }
                }
                
                runtime-attributes = """
                    Int runtime_minutes = 600
                    Int cpu = 1
                    Int memory_mb = 4096
                    String? docker
                    String? docker_user
                """
                
                submit = """
                    sbatch \
                        --wait \
                        -J ${job_name} \
                        -D ${cwd} \
                        -o ${out} \
                        -e ${err} \
                        -t ${runtime_minutes} \
                        ${"-c " + cpu} \
                        --mem ${memory_mb} \
                        --wrap "/bin/bash ${script}"
                    rm -r ${cwd}/inputs
                    rm -r ${cwd}/tmp.*
                """

                # It is HIGHLY recommended and A LOT faster to use
                # `udocker create --name=<name> <image>`
                # and reference the docker image by <name> in the WDL docker argument.
                # Just using `udocker run <image>` will create a new container every time!
                # Some of the containers are very large and take hours to create.
                # Otherwise, uncomment the first line of the submit-docker command:
                submit-docker = """
                    # udocker pull ${docker}
                    sbatch \
                        --wait \
                        -J ${job_name} \
                        -D ${cwd} \
                        -o ${out} \
                        -e ${err} \
                        -t ${runtime_minutes} \
                        ${"-c " + cpu} \
                        --mem ${memory_mb} \
                        --wrap "\
                            udocker run \
                                -v ${cwd} \
                                -v ${cwd}:${docker_cwd} \
                                ${docker} \
                                ${job_shell} \
                                ${docker_script}
                        "
                    rm -r ${cwd}/inputs
                    rm -r ${cwd}/tmp.*
                """

                kill = "scancel ${job_id}"
                check-alive = "squeue -j ${job_id}"
                job-id-regex = "Submitted batch job (\\d+).*"
            }
        }
    }
}
